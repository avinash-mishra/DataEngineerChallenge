{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amishra/github/paypay_avinash/DataEngineerChallenge/src/utils/libraries.py:16: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "# Libraries and setup\n",
    "\n",
    "# Auto reload changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "from src.utils.dependencies import *\n",
    "# from src.utils.utility import Utility\n",
    "# utl = Utility()\n",
    "\n",
    "# log file schema\n",
    "from src.log_file_schema import *\n",
    "\n",
    "# data handler\n",
    "from src.data_handler import DataHandler\n",
    "dh = DataHandler()\n",
    "n=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Get Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create or get spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"PayPayChallenge\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log file locationn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration(start, end):\n",
    "        try:\n",
    "            num_of_seconds = (end - start).total_seconds()\n",
    "        except:\n",
    "            num_of_seconds = 0\n",
    "        return num_of_seconds\n",
    "get_duration = udf(duration, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_session_time(df_ip_session):\n",
    "    window_func_session = Window.partitionBy(\"ip_session_count\").orderBy(\"current_timestamp\")\n",
    "    df_session = df_ip_session.withColumn(\"previous_timestamp_session\",\n",
    "                              lag(df_ip_session[\"current_timestamp\"]).over(window_func_session)) \\\n",
    "                  .withColumn(\"current_session_duration\",\n",
    "                              get_duration(col(\"previous_timestamp_session\"), col(\"current_timestamp\")))\n",
    "    df_session_total = df_session.groupby(\"ip_session_count\").agg(\n",
    "            sum(\"current_session_duration\").alias(\"total_session_time\")).cache()\n",
    "    df_session_avg = df_session_total.select([mean(\"total_session_time\").alias(\"avg_session_time\")]).cache()\n",
    "    df_session_avg.show()\n",
    "    return df_session\n",
    "\n",
    "\n",
    "def count_unique_request(df_session):\n",
    "    df_unique_url = df_session.groupby(\"ip_session_count\").agg(\n",
    "        countDistinct(\"request_url\").alias(\"count_unique_requests\"))\n",
    "    df_unique_url.show()\n",
    "\n",
    "def get_longest_session_time(df_session):\n",
    "    df_ip_time = df_session.groupby(\"client_ip\").agg(\n",
    "                sum(\"session_duration\").alias(\"session_time_all\"),\n",
    "                count(\"client_ip\").alias(\"num_sessions\"),\n",
    "                max(\"session_duration\").alias(\"session_duration_max\")) \\\n",
    "          .withColumn(\"avg_session_time\", col(\"session_time_all\") / col(\"num_sessions\")) \\\n",
    "          .orderBy(col(\"avg_session_time\"), ascending=False)\n",
    "    df_ip_time.show()\n",
    "\n",
    "\n",
    "num_partitions = 15\n",
    "session_time = 15*60\n",
    "def solve(spark):\n",
    "    df_logs = dh.initialization(spark).cache()\n",
    "    # print(df_logs.limit(5).toPandas().head(5))\n",
    "    df_ip_session = dh.preprocess(df_logs, gd=get_duration).repartition(num_partitions).cache()\n",
    "    df_session = average_session_time(df_ip_session).repartition(num_partitions).cache()\n",
    "    count_unique_request(df_session)\n",
    "    get_longest_session_time(df_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve(spark=spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}