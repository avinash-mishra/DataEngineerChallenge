{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Libraries and setup\n",
    "\n",
    "# Auto reload changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.utils.dependencies import *\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from fbprophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# log file schema\n",
    "from src.log_file_schema import schema\n",
    "\n",
    "# data handler\n",
    "from src.data_handler import DataHandler\n",
    "dh = DataHandler()\n",
    "n=5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create or Get Spark session"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#create or get spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"PayPayChallenge\")\\\n",
    "    .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+------+------+------+\n",
      "|count_unique_URLs|octet0|octet1|octet2|octet3|\n",
      "+-----------------+------+------+------+------+\n",
      "|               84|   113|   193|   114|    25|\n",
      "|               85|   115|   112|   250|   108|\n",
      "|                2|   117|   203|   181|   144|\n",
      "|                7|   120|    61|    47|    36|\n",
      "|               88|   124|   125|    22|   218|\n",
      "|              108|    14|   139|    82|   134|\n",
      "|                9|   117|   247|   188|    13|\n",
      "|              112|    27|    34|   244|   251|\n",
      "|                3|   117|   207|    97|   173|\n",
      "|               16|    61|    16|   142|   162|\n",
      "|               34|   117|   241|   152|    20|\n",
      "|               10|   123|   136|   182|   137|\n",
      "|              110|   202|    53|    89|   132|\n",
      "|               16|   202|   174|    92|    10|\n",
      "|               14|    59|   160|   110|   163|\n",
      "|               16|   117|   205|    39|   248|\n",
      "|                6|    27|    63|   186|    72|\n",
      "|               94|   103|    16|    71|     9|\n",
      "|                8|   117|   199|   175|   119|\n",
      "|                7|   123|    63|   194|   202|\n",
      "+-----------------+------+------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def duration(start, end):\n",
    "    try:\n",
    "        num_of_seconds = (end - start).total_seconds()\n",
    "    except:\n",
    "        num_of_seconds = 0\n",
    "    return num_of_seconds;\n",
    "\n",
    "get_duration = udf(duration, FloatType())\n",
    "\n",
    "def preprocess_data(spark):\n",
    "\n",
    "    df = spark.read.csv(log_file, schema=schema, sep=\" \").repartition(num_partitions).cache()\n",
    "    split_client = split(df[\"client:port\"], \":\")\n",
    "    split_backend = split(df[\"backend:port\"], \":\")\n",
    "    split_request = split(df[\"request\"], \" \")\n",
    "\n",
    "    df=df.withColumn(\"ip\", split_client.getItem(0)) \\\n",
    "                .withColumn(\"client_port\", split_client.getItem(1)) \\\n",
    "                .withColumn(\"backend_ip\", split_backend.getItem(0)) \\\n",
    "                .withColumn(\"backend_port\", split_backend.getItem(1)) \\\n",
    "                .withColumn(\"request_action\", split_request.getItem(0)) \\\n",
    "                .withColumn(\"request_url\", split_request.getItem(1)) \\\n",
    "                .withColumn(\"request_protocol\", split_request.getItem(2)) \\\n",
    "                .withColumn(\"current_timestamp\", col(\"timestamp\").cast(\"timestamp\")) \\\n",
    "                .drop(\"client:port\",\"backend:port\",\"request\").cache()\n",
    "\n",
    "    df=df.select([\"ip\", \"request_url\"]);\n",
    "    \n",
    "    \n",
    "    df=df.na.drop(subset=[\"request_url\"])\n",
    "    df=df.na.drop(subset=[\"ip\"])\n",
    "    \n",
    "    df = df.groupby(\"ip\").agg(countDistinct(\"request_url\").alias(\"count_unique_URLs\"));\n",
    "    df=df.na.drop(subset=[\"count_unique_URLs\"])\n",
    "    \n",
    "    splitt2=split(df[\"ip\"], \"\\\\.\");\n",
    "    df=df.withColumn(\"octet0\", splitt2.getItem(0));\n",
    "    df=df.withColumn(\"octet1\", splitt2.getItem(1));\n",
    "    df=df.withColumn(\"octet2\", splitt2.getItem(2));\n",
    "    df=df.withColumn(\"octet3\", splitt2.getItem(3));\n",
    "    df=df.drop(\"ip\");\n",
    "    df=df.na.drop(subset=[\"octet0\"])\n",
    "    df=df.na.drop(subset=[\"octet1\"])\n",
    "    df=df.na.drop(subset=[\"octet2\"])\n",
    "    df=df.na.drop(subset=[\"octet3\"])\n",
    "    #print(df.dtypes);\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def data_loader(spark):\n",
    "    dataset3 = preprocess_data(spark).cache()\n",
    "    dataset3.show();\n",
    "    return dataset3.select(\"*\").toPandas();\n",
    "\n",
    "df=data_loader(spark)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  octet0 octet1 octet2 octet3  count_unique_URLs\n",
      "0    113    193    114     25                 84\n",
      "1    115    112    250    108                 85\n",
      "2    117    203    181    144                  2\n",
      "3    120     61     47     36                  7\n",
      "4    124    125     22    218                 88\n",
      "(90544, 5)\n"
     ]
    }
   ],
   "source": [
    "df=df[['octet0', 'octet1', 'octet2', 'octet3', 'count_unique_URLs']]\n",
    "\n",
    "print(df.head());\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amishra/miniconda3/envs/paypay_challenge/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 94.75591607234915\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "df=df.apply(pd.to_numeric) ;\n",
    "\n",
    "X = df[['octet0', 'octet1', 'octet2', 'octet3']]\n",
    "Y =df[['count_unique_URLs']]\n",
    "model = xgboost.XGBRegressor(objective='reg:squarederror')\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "#print(results);\n",
    "print(\"RMSE:\", np.mean(np.sqrt(np.abs(results))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-6f5bc5d150c1>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model_rf.fit(X, Y)\n",
      "/Users/amishra/miniconda3/envs/paypay_challenge/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "/Users/amishra/miniconda3/envs/paypay_challenge/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/amishra/miniconda3/envs/paypay_challenge/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/amishra/miniconda3/envs/paypay_challenge/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/amishra/miniconda3/envs/paypay_challenge/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/amishra/miniconda3/envs/paypay_challenge/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/amishra/miniconda3/envs/paypay_challenge/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/amishra/miniconda3/envs/paypay_challenge/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/amishra/miniconda3/envs/paypay_challenge/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/amishra/miniconda3/envs/paypay_challenge/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/amishra/miniconda3/envs/paypay_challenge/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Randomforest: 81.32694452233947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_rf = RandomForestRegressor()\n",
    "model_rf.fit(X, Y)\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(model_rf, X, Y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "#print(results);\n",
    "print(\"RMSE Randomforest:\", np.mean(np.sqrt(np.abs(results))))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}